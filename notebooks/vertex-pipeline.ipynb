{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p _artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GCP_PROJECT_ID = os.environ[\"GCP_PROJECT_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/penguins/.venv/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp import components\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    InputPath,\n",
    "    OutputPath,\n",
    "    Output,\n",
    "    Dataset,\n",
    "    Metrics,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\"],\n",
    "    output_component_file=\"_artifacts/query.yaml\",\n",
    ")\n",
    "def query(\n",
    "    query: str, output_path: OutputPath(\"Dataset\"), project_id: Optional[str] = None\n",
    ") -> None:\n",
    "    \"\"\"Calculates sum of two arguments\"\"\"\n",
    "\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    job = client.query(query)\n",
    "\n",
    "    df = job.to_dataframe()\n",
    "    df.to_parquet(output_path)\n",
    "\n",
    "\n",
    "train_model = components.load_component_from_text(\n",
    "    f\"\"\"\n",
    "name: Train model\n",
    "description: Trains our model\n",
    "\n",
    "inputs:\n",
    "- {{name: train_dataset, type: Dataset, description: 'Train dataset'}}\n",
    "\n",
    "outputs:\n",
    "- {{name: model, type: Model, description: 'Output model'}}\n",
    "\n",
    "implementation:\n",
    "  container:\n",
    "    image: europe-west1-docker.pkg.dev/{GCP_PROJECT_ID}/vertex/penguin_model\n",
    "    command: [\n",
    "      penguin-model, \n",
    "      {{inputPath: train_dataset}},\n",
    "      {{outputPath: model}}\n",
    "    ]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\", output_component_file=\"_artifacts/eval_model.yaml\"\n",
    ")\n",
    "def eval_model(\n",
    "    model_path: InputPath(\"Model\"), metrics: Output[Metrics]\n",
    ") -> NamedTuple(\"EvalModelOutput\", [(\"roc\", float)]):\n",
    "    print(model_path)\n",
    "\n",
    "    metrics.log_metric(\"roc\", 0.9)\n",
    "\n",
    "\n",
    "@kfp.dsl.pipeline(name=\"penguin\")\n",
    "def pipeline():\n",
    "\n",
    "    query_task = query(\n",
    "        \"SELECT * FROM bigquery-public-data.ml_datasets.penguins\",\n",
    "        project_id=GCP_PROJECT_ID,\n",
    "    )\n",
    "\n",
    "    train_task = (\n",
    "        train_model(query_task.outputs[\"output_path\"])\n",
    "        # Docs: https://www.kubeflow.org/docs/distributions/gke/pipelines/enable-gpu-and-tpu/\n",
    "        # .set_gpu_limit(1).add_node_selector_constraint(\n",
    "        #     \"cloud.google.com/gke-accelerator\", \"nvidia-tesla-k80\"\n",
    "        # )\n",
    "    )\n",
    "\n",
    "    eval_model(train_task.outputs[\"model\"])\n",
    "\n",
    "    # model_upload_op = gcc_aip.ModelUploadOp(\n",
    "    #     project=project,\n",
    "    #     display_name=model_display_name,\n",
    "    #     artifact_uri=WORKING_DIR,\n",
    "    #     serving_container_image_uri=serving_container_image_uri,\n",
    "    #     # serving_container_environment_variables={\"NOT_USED\": \"NO_VALUE\"},\n",
    "    # )\n",
    "    # model_upload_op.after(train_task)\n",
    "\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"_artifacts/pipeline.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/1035892568606/locations/europe-west1/pipelineJobs/penguin-20211119123746\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/1035892568606/locations/europe-west1/pipelineJobs/penguin-20211119123746')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west1/pipelines/runs/penguin-20211119123746?project=1035892568606\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/1035892568606/locations/europe-west1/pipelineJobs/penguin-20211119123746 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/1035892568606/locations/europe-west1/pipelineJobs/penguin-20211119123746 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.aiplatform.pipeline_jobs import PipelineJob\n",
    "\n",
    "job = PipelineJob(\n",
    "    display_name=\"penguins\",\n",
    "    enable_caching=False,\n",
    "    template_path=\"_artifacts/pipeline.json\",\n",
    "    parameter_values={},\n",
    "    pipeline_root=f\"gs://{GCP_PROJECT_ID}-penguin-artifacts/pipelines\",\n",
    "    location=\"europe-west1\",\n",
    ")\n",
    "\n",
    "job.run(\n",
    "    service_account=f\"vmd-penguin@{GCP_PROJECT_ID}.iam.gserviceaccount.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79885e6b11e7f47e45d3c7f9fa1c0c54f79af98e17e17b31cc5f2ccf50de5c40"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('.venv': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
