{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "job = client.query(\"SELECT * FROM `bigquery-public-data`.ml_datasets.penguins\")\n",
    "df = job.to_dataframe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>36.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>39.8</td>\n",
       "      <td>19.1</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4650.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>40.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>46.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>192.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Dream</td>\n",
       "      <td>37.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     species island  culmen_length_mm  \\\n",
       "0        Adelie Penguin (Pygoscelis adeliae)  Dream              36.6   \n",
       "1        Adelie Penguin (Pygoscelis adeliae)  Dream              39.8   \n",
       "2        Adelie Penguin (Pygoscelis adeliae)  Dream              40.9   \n",
       "3  Chinstrap penguin (Pygoscelis antarctica)  Dream              46.5   \n",
       "4        Adelie Penguin (Pygoscelis adeliae)  Dream              37.3   \n",
       "\n",
       "   culmen_depth_mm  flipper_length_mm  body_mass_g     sex  \n",
       "0             18.4              184.0       3475.0  FEMALE  \n",
       "1             19.1              184.0       4650.0    MALE  \n",
       "2             18.9              184.0       3900.0    MALE  \n",
       "3             17.9              192.0       3500.0  FEMALE  \n",
       "4             16.8              192.0       3000.0  FEMALE  "
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train = df[[\"species\", \"island\", \"sex\"]].dropna().loc[lambda row: row.sex != \".\"]\n",
    "\n",
    "x = train.drop(\"sex\", axis=1)\n",
    "y = train[\"sex\"].map({'MALE':0, 'FEMALE':1}).astype(int)\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"feature_engineering\", \n",
    "            ColumnTransformer(\n",
    "              transformers=[(\"one_hot\", OneHotEncoder(), [\"species\", \"island\"])],\n",
    "              remainder=\"drop\"\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"model\",\n",
    "            RandomForestClassifier()\n",
    "        )       \n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(x, y)\n",
    "model.predict(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "import kfp\n",
    "from kfp.v2.compiler import Compiler\n",
    "from kfp import components as comp\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from google.cloud.aiplatform.pipeline_jobs import PipelineJob\n",
    "from google.cloud.aiplatform import Model\n",
    "\n",
    "project_id = \"cde-ds-enablement-8k1r\"\n",
    "region = \"europe-west1\"\n",
    "pipeline_root_path = \"gs://cde-dse-test-artifacts/penguin-model\"\n",
    "\n",
    "\n",
    "def _train_model():\n",
    "    \"\"\"Trains our penguin model.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    # from google.cloud import storage\n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    import joblib\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    client = bigquery.Client(project=os.environ[\"CLOUD_ML_PROJECT_ID\"])    \n",
    "    data = client.query(\"SELECT * FROM `bigquery-public-data`.ml_datasets.penguins\").to_dataframe()\n",
    "    \n",
    "    train = data[[\"species\", \"island\", \"sex\"]].dropna().loc[lambda row: row.sex != \".\"]\n",
    "\n",
    "    x = train.drop(\"sex\", axis=1)\n",
    "    y = train[\"sex\"].map({'MALE':0, 'FEMALE':1}).astype(int)\n",
    "\n",
    "    model = Pipeline(\n",
    "        steps=[\n",
    "            (\n",
    "                \"feature_engineering\", \n",
    "                ColumnTransformer(\n",
    "                  transformers=[(\"one_hot\", OneHotEncoder(), [\"species\", \"island\"])],\n",
    "                  remainder=\"drop\"\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                \"model\",\n",
    "                RandomForestClassifier()\n",
    "            )       \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    # Save model artifact to local filesystem (doesn't persist)\n",
    "    with Path(\"/gcs/cde-dse-test-outputs/model.pkl\").open(\"wb\") as file_:\n",
    "        joblib.dump(model, file_)\n",
    "\n",
    "\n",
    "train_model = comp.create_component_from_func(\n",
    "    _train_model,\n",
    "    packages_to_install=[\n",
    "        \"scikit-learn\", \n",
    "        \"google-cloud-bigquery\", \n",
    "        \"google-cloud-storage\", \n",
    "        \"pandas\", \n",
    "        \"pyarrow\"\n",
    "    ]\n",
    ")\n",
    "    \n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "    name=\"penguins\",\n",
    "    pipeline_root=pipeline_root_path)\n",
    "def pipeline():\n",
    "    train_model()\n",
    "\n",
    "    \n",
    "Compiler().compile(\n",
    "    pipeline_func=pipeline, \n",
    "    package_path='pipeline.json'\n",
    ")\n",
    "\n",
    "\n",
    "job = PipelineJob(\n",
    "    display_name=\"My first penguin pipeline\",\n",
    "    enable_caching=False,\n",
    "    template_path=\"pipeline.json\",\n",
    "    parameter_values={},\n",
    "    pipeline_root=pipeline_root_path,\n",
    "    location=region,\n",
    ")\n",
    "\n",
    "job.run(service_account=\"cde-dse-test-pipeline@cde-ds-enablement-8k1r.iam.gserviceaccount.com\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/409590257761/locations/europe-west1/pipelineJobs/penguins-20211021063307\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/409590257761/locations/europe-west1/pipelineJobs/penguins-20211021063307')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west1/pipelines/runs/penguins-20211021063307?project=409590257761\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/409590257761/locations/europe-west1/pipelineJobs/penguins-20211021063307 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/409590257761/locations/europe-west1/pipelineJobs/penguins-20211021063307 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/409590257761/locations/europe-west1/pipelineJobs/penguins-20211021063307 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/409590257761/locations/europe-west1/pipelineJobs/penguins-20211021063307 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [train-model].; Job (project_id = cde-ds-enablement-8k1r, job_id = 1949495688698003456) is failed due to the above error.; Failed to handle the job: {project_number = 409590257761, job_id = 1949495688698003456}\"\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10404/179269628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vertex-julian@cde-ds-enablement-8k1r.iam.gserviceaccount.com\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"View Pipeline Job:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashboard_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [train-model].; Job (project_id = cde-ds-enablement-8k1r, job_id = 1949495688698003456) is failed due to the above error.; Failed to handle the job: {project_number = 409590257761, job_id = 1949495688698003456}\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "Model.upload"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Model.upload of <class 'google.cloud.aiplatform.models.Model'>>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}